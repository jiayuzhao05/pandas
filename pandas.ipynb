{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series: a one-dimensional labeled array holding data of any type\n",
    "\n",
    "DataFrame: a two-dimensional data structure that holds data like a two-dimension array or a table with rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range(\"20130101\", periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\"ABCD\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": 1.0,\n",
    "        \"B\": pd.Timestamp(\"20130102\"),\n",
    "        \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n",
    "        \"D\": np.array([3] * 4, dtype=\"int32\"),\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "        \"F\": \"foo\",\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.index\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return a NumPy representation of the underlying data with DataFrame.to_numpy() without the index or column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df2.dtypes\n",
    "df2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()  # shows a quick statistic summary of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.T # Transposing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)  # DataFrame.sort_index() sorts by an axis\n",
    "# DataFrame.sort_values() sorts by sort_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getitem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a DataFrame, passing a single label selects a columns and yields a Series equivalent to df.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df[\"A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[dates[0]]  # Selecting a row matching a label\n",
    "df.loc[:, [\"A\", \"B\"]] # Selecting all rows (:) with a select column labels\n",
    "df.loc[\"20130102\":\"20130104\", [\"A\", \"B\"]] # For label slicing, both endpoints are included\n",
    "df.loc[dates[0], \"A\"]  # Selecting a single row and column label returns a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[3]  # Select via the position of the passed integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[3:5, 0:2]  # Integer slices acts similar to NumPy/Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[[1, 2, 4], [0, 2]]  # Lists of integer position locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[1:3, :]   # For slicing rows explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.iat[1, 1]  # For getting fast access to a scalar (equivalent to the prior method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df[df[\"A\"] > 0]  # Select rows where df.A is greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df[df > 0]  # Selecting values from a DataFrame where a boolean condition is met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"E\"] = [\"one\", \"one\", \"two\", \"three\", \"four\", \"three\"]\n",
    "df2\n",
    "df2[df2[\"E\"].isin([\"two\", \"four\"])]  # Using isin() method for filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([1, 2, 3, 4, 5, 6], index=pd.date_range(\"20130102\", periods=6))\n",
    "# Setting a new column automatically aligns the data by the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.at[dates[0], \"A\"] = 0 # Setting values by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.iat[0, 1] = 0 # Setting values by position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[:, \"D\"] = np.array([5] * len(df))  # Setting by assigning with a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df1.dropna(how=\"any\") # DataFrame.dropna() drops any rows that have missing data\n",
    "df1.fillna(value=5)  # DataFrame.fillna() fills missing data\n",
    "pd.isna(df1) # isna()  gets the boolean mask where values are nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.agg(lambda x: np.mean(x) * 5.6)\n",
    "df.transform(lambda x: x * 101.2)\n",
    "# DataFrame.agg() and DataFrame.transform() applies a user defined function that reduces or broadcasts its result respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randint(0, 7, size=10))\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.Series([\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "## Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "pieces = [df[:3], df[3:7], df[7:]] # break it into pieces\n",
    "pd.concat(pieces)\n",
    "# Concatenating pandas objects together row-wise with concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"key\": [\"foo\", \"foo\"], \"lval\": [1, 2]})\n",
    "right = pd.DataFrame({\"key\": [\"foo\", \"foo\"], \"rval\": [4, 5]})\n",
    "left\n",
    "right\n",
    "pd.merge(left, right, on=\"key\")  # merge() enables SQL style join types along specific columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n",
    "        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n",
    "        \"C\": np.random.randn(8),\n",
    "        \"D\": np.random.randn(8),\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby([\"A\", \"B\"]).sum()  # Grouping by multiple columns label forms MultiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "arrays = [\n",
    "   [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n",
    "   [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n",
    "]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=[\"first\", \"second\"])\n",
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[\"A\", \"B\"])\n",
    "df2 = df[:4]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "stacked = df2.stack(future_stack=True)\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a “stacked” DataFrame or Series (having a MultiIndex as the index), the inverse operation of stack() is unstack(), which by default unstacks the last level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "stacked.unstack()\n",
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"one\", \"one\", \"two\", \"three\"] * 3,\n",
    "        \"B\": [\"A\", \"B\", \"C\"] * 4,\n",
    "        \"C\": [\"foo\", \"foo\", \"foo\", \"bar\", \"bar\", \"bar\"] * 2,\n",
    "        \"D\": np.random.randn(12),\n",
    "        \"E\": np.random.randn(12),\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pivot_table() pivots a DataFrame specifying the values, index and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values=\"D\", index=[\"A\", \"B\"], columns=[\"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas has simple, powerful, and efficient functionality for performing resampling operations during frequency conversion (e.g., converting secondly data into 5-minutely data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rng = pd.date_range(\"1/1/2012\", periods=100, freq=\"s\")\n",
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n",
    "ts.resample(\"5Min\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rng = pd.date_range(\"3/6/2012 00:00\", periods=5, freq=\"D\")\n",
    "ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "\n",
    "ts_utc = ts.tz_localize(\"UTC\")  # Series.tz_localize() localizes a time series to a time zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the categories and simultaneously add the missing categories (methods under  Series.cat() return a new Series by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df[\"grade\"] = df[\"grade\"].cat.set_categories(\n",
    "    [\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range(\"1/1/2000\", periods=1000))\n",
    "\n",
    "ts = ts.cumsum()\n",
    "\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.random.randn(1000, 4), index=ts.index, columns=[\"A\", \"B\", \"C\", \"D\"]\n",
    ")\n",
    "\n",
    "df = df.cumsum()\n",
    "plt.figure()\n",
    "\n",
    "df.plot()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and exporting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(0, 5, (10, 5)))\n",
    "df.to_csv(\"foo.csv\")\n",
    "\n",
    "pd.read_csv(\"foo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_parquet(\"foo.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"foo.xlsx\", sheet_name=\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_excel(\"foo.xlsx\", \"Sheet1\", index_col=None, na_values=[\"NA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotchas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# task 1 从CSV文件构建数据框架\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def build_morg_df(file_name):\n",
    "    if not os.path.exists(file_name):\n",
    "        return None\n",
    "    \n",
    "    # Read the main MORG file\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # Read code files and create mapping dictionaries\n",
    "    gender_codes = pd.read_csv('gender_code.csv').set_index('gender_code')['gender_string'].to_dict()\n",
    "    race_codes = pd.read_csv('race_code.csv').set_index('race_code')['race_string'].to_dict()\n",
    "    ethnicity_codes = pd.read_csv('ethnic_code.csv').set_index('ethnic_code')['ethnic_string'].to_dict()\n",
    "    employment_status_codes = pd.read_csv('employment_status_code.csv').set_index('employment_status_code')['employment_status_string'].to_dict()\n",
    "    \n",
    "    # Map codes to strings\n",
    "    df['gender'] = df['gender'].map(gender_codes)\n",
    "    df['race'] = df['race'].map(race_codes)\n",
    "    df['ethnicity'] = df['ethnicity'].map(ethnicity_codes)\n",
    "    df['employment_status'] = df['employment_status'].map(employment_status_codes)\n",
    "    \n",
    "    # Ensure correct column order\n",
    "    df = df[['h_id', 'age', 'gender', 'race', 'ethnicity', 'employment_status', 'hours_worked_per_week', 'earnings_per_week']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_weekly_earnings_stats_for_fulltime_workers(morg_df, gender, race, ethnicity):\n",
    "    # Filter for full-time workers\n",
    "    fulltime_workers = morg_df[(morg_df['employment_status'] == 'Working') & \n",
    "                               (morg_df['hours_worked_per_week'] >= 35)]\n",
    "    \n",
    "    # Apply gender filter\n",
    "    if gender != \"All\":\n",
    "        fulltime_workers = fulltime_workers[fulltime_workers['gender'] == gender]\n",
    "    \n",
    "    # Apply race filter\n",
    "    if race != \"All\":\n",
    "        fulltime_workers = fulltime_workers[fulltime_workers['race'] == race]\n",
    "    \n",
    "    # Apply ethnicity filter\n",
    "    if ethnicity != \"All\":\n",
    "        fulltime_workers = fulltime_workers[fulltime_workers['ethnicity'] == ethnicity]\n",
    "    \n",
    "    # Calculate statistics\n",
    "    if fulltime_workers.empty:\n",
    "        return (0.0, 0.0, 0.0, 0.0)\n",
    "    \n",
    "    avg_earnings = fulltime_workers['earnings_per_week'].mean()\n",
    "    median_earnings = fulltime_workers['earnings_per_week'].median()\n",
    "    min_earnings = fulltime_workers['earnings_per_week'].min()\n",
    "    max_earnings = fulltime_workers['earnings_per_week'].max()\n",
    "    \n",
    "    return (avg_earnings, median_earnings, min_earnings, max_earnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_unemployment_rates(filename_list, age_range, var_of_interest):\n",
    "    # Initialize a dictionary to store results\n",
    "    results = {}\n",
    "\n",
    "    for file_name in filename_list:\n",
    "        # Extract year from file name\n",
    "        year = file_name.split('_')[1][1:3]\n",
    "        \n",
    "        # Read the data\n",
    "        df = pd.read_csv(file_name)\n",
    "        \n",
    "        # Filter by age range\n",
    "        age_filtered = df[(df['age'] >= age_range[0]) & (df['age'] <= age_range[1])]\n",
    "        \n",
    "        # Initialize a dictionary for the current year\n",
    "        year_results = {}\n",
    "        \n",
    "        # Calculate unemployment rates for each category\n",
    "        for category in age_filtered[var_of_interest].unique():\n",
    "            category_data = age_filtered[age_filtered[var_of_interest] == category]\n",
    "            total = category_data.shape[0]\n",
    "            unemployed = category_data[category_data['employment_status'].isin(['Layoff', 'Looking'])].shape[0]\n",
    "            \n",
    "            # Calculate unemployment rate\n",
    "            rate = unemployed / total if total > 0 else 0.0\n",
    "            year_results[category] = rate\n",
    "        \n",
    "        # Store results for the year\n",
    "        results[year] = year_results\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    result_df = pd.DataFrame(results).fillna(0.0)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_unemployment_rates(filename_list, age_range, var_of_interest):\n",
    "    \"\"\"\n",
    "    计算特定人群的失业率\n",
    "    \n",
    "    Args:\n",
    "        filename_list: CPS MORG数据文件列表\n",
    "        age_range: (年龄下限, 年龄上限)的元组\n",
    "        var_of_interest: 分类变量 ('GENDER', 'RACE', 或 'ETHNIC')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 包含各年份各类别失业率的数据框架，如果输入无效则返回None\n",
    "    \"\"\"\n",
    "    # 验证输入参数\n",
    "    if not filename_list or not isinstance(age_range, tuple) or len(age_range) != 2:\n",
    "        return None\n",
    "    \n",
    "    if age_range[0] > age_range[1]:\n",
    "        return None\n",
    "        \n",
    "    # 验证var_of_interest\n",
    "    valid_vars = {'GENDER', 'RACE', 'ETHNIC'}\n",
    "    if var_of_interest not in valid_vars:\n",
    "        return None\n",
    "    \n",
    "    # 初始化结果字典\n",
    "    results = {}\n",
    "    \n",
    "    for filename in filename_list:\n",
    "        # 从文件名提取年份\n",
    "        try:\n",
    "            year = filename.split('_d')[1][:2]\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # 读取CSV文件\n",
    "            df = pd.read_csv(filename)\n",
    "            \n",
    "            # 按年龄范围筛选\n",
    "            mask = (df['age'] >= age_range[0]) & (df['age'] <= age_range[1])\n",
    "            age_filtered = df[mask]\n",
    "            \n",
    "            # 计算每个类别的失业率\n",
    "            year_results = {}\n",
    "            \n",
    "            # 获取该变量的所有唯一值\n",
    "            categories = age_filtered[var_of_interest.lower()].unique()\n",
    "            \n",
    "            for category in categories:\n",
    "                category_data = age_filtered[age_filtered[var_of_interest.lower()] == category]\n",
    "                total_count = len(category_data)\n",
    "                \n",
    "                if total_count == 0:\n",
    "                    year_results[category] = 0.0\n",
    "                    continue\n",
    "                    \n",
    "                # 计算失业人数（状态为'Layoff'或'Looking'）\n",
    "                unemployed = category_data[\n",
    "                    category_data['employment_status'].isin(['Layoff', 'Looking'])\n",
    "                ].shape[0]\n",
    "                \n",
    "                # 计算失业率\n",
    "                year_results[category] = unemployed / total_count\n",
    "                \n",
    "            results[year] = year_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"处理文件 {filename} 时出错: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # 如果没有成功处理任何文件，返回None\n",
    "    if not results:\n",
    "        return None\n",
    "        \n",
    "    # 将结果转换为DataFrame并填充缺失值为0.0\n",
    "    result_df = pd.DataFrame(results).fillna(0.0)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 按性别统计50-70岁人群的失业率\n",
    "files = [\"data/morg_d14.csv\", \"data/morg_d10.csv\", \"data/morg_d07.csv\"]\n",
    "result = calculate_unemployment_rates(files, (50, 70), \"GENDER\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def pandas_practice(morg_df):\n",
    "    \"\"\"\n",
    "    执行各种pandas数据提取操作\n",
    "    \n",
    "    Args:\n",
    "        morg_df: MORG数据的DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 包含所有任务结果的元组\n",
    "    \"\"\"\n",
    "    # 任务2：提取age列\n",
    "    age_column = morg_df['age']\n",
    "    \n",
    "    # 任务3：提取h_id为1_2_2的行\n",
    "    row_1_2_2 = morg_df[morg_df['h_id'] == '1_2_2']\n",
    "    \n",
    "    # 任务4：提取前四行\n",
    "    first_four_rows = morg_df[:4]\n",
    "    \n",
    "    # 任务5：提取每周工作35小时或以上的行\n",
    "    full_time_workers = morg_df[morg_df['hours_worked_per_week'] >= 35]\n",
    "    \n",
    "    return (age_column, row_1_2_2, first_four_rows, full_time_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def process_h_id(morg_df):\n",
    "    \"\"\"\n",
    "    处理h_id列，提取和转换特定部分\n",
    "    \n",
    "    Args:\n",
    "        morg_df: 包含h_id列的DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (first_last_df, middle_numbers)\n",
    "            - first_last_df: 包含第一个和最后一个数字的DataFrame\n",
    "            - middle_numbers: 包含中间数字的Series\n",
    "    \"\"\"\n",
    "    # 验证输入\n",
    "    if 'h_id' not in morg_df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'h_id' column\")\n",
    "    \n",
    "    # 验证状态代码范围\n",
    "    if not morg_df['employment_status'].between(1, 7).all():\n",
    "        raise ValueError(\"Employment status codes must be between 1 and 7\")\n",
    "    \n",
    "    # 验证工作时间是否为非负数\n",
    "    if (morg_df['hours_worked_per_week'] < 0).any():\n",
    "        raise ValueError(\"Hours worked cannot be negative\")\n",
    "        \n",
    "    # 验证h_id格式\n",
    "    if not all(morg_df['h_id'].str.match(r'^\\d+_\\d+_\\d+$')):\n",
    "        raise ValueError(\"All h_id values must be in format 'number_number_number'\")\n",
    "\n",
    "    # 任务6：创建包含第一个和最后一个数字的DataFrame\n",
    "    # 将h_id拆分成三部分\n",
    "    split_ids = morg_df['h_id'].str.split('_')\n",
    "    \n",
    "    # 提取第一个和最后一个数字\n",
    "    first_numbers = split_ids.str[0]\n",
    "    last_numbers = split_ids.str[2]\n",
    "    \n",
    "    # 创建新的DataFrame\n",
    "    first_last_df = pd.DataFrame({\n",
    "        'first_num': first_numbers,\n",
    "        'last_num': last_numbers\n",
    "    })\n",
    "    \n",
    "    # 任务7：提取中间数字\n",
    "    # 使用strip()移除第一个和最后一个数字及其下划线\n",
    "    middle_numbers = morg_df['h_id'].str.strip(first_numbers + '_').str.strip('_' + last_numbers)\n",
    "    \n",
    "    return (first_last_df, middle_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def process_employment_data(morg_df):\n",
    "    \"\"\"\n",
    "    处理就业相关数据，包括状态转换和数据筛选\n",
    "    \n",
    "    Args:\n",
    "        morg_df: MORG数据的DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (status_converted_df, not_working, full_time_workers)\n",
    "            - status_converted_df: 状态转换后的DataFrame\n",
    "            - not_working: 不工作的人对应的行\n",
    "            - full_time_workers: 全职工作者对应的行\n",
    "    \"\"\"\n",
    "    # 创建DataFrame的副本以避免修改原始数据\n",
    "    df = morg_df.copy()\n",
    "    \n",
    "    # 任务9：将状态代码转换为分类值\n",
    "    status_categories = [\n",
    "        'Working',      # 1\n",
    "        'Absent',       # 2\n",
    "        'Layoff',       # 3\n",
    "        'Looking',      # 4\n",
    "        'Retired',      # 5\n",
    "        'Disabled',     # 6\n",
    "        'Other'         # 7\n",
    "    ]\n",
    "    \n",
    "    # 将状态代码转换为分类值并重命名列\n",
    "    df['employment_status'] = pd.Categorical.from_codes(\n",
    "        df['employment_status'] - 1,  # 减1是因为代码从1开始而不是0\n",
    "        categories=status_categories\n",
    "    )\n",
    "    \n",
    "    # 任务10：提取不工作的人\n",
    "    # 不工作包括：Layoff, Looking, Retired, Disabled, Other\n",
    "    not_working = df[df['employment_status'].isin([\n",
    "        'Layoff', 'Looking', 'Retired', 'Disabled', 'Other'\n",
    "    ])]\n",
    "    \n",
    "    # 任务11：提取全职工作者\n",
    "    # 工作状态为\"Working\"且每周工作时间>=35小时\n",
    "    full_time_workers = df[\n",
    "        (df['employment_status'] == 'Working') & \n",
    "        (df['hours_worked_per_week'] >= 35)\n",
    "    ]\n",
    "    \n",
    "    return (df, not_working, full_time_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def show_bin_ranges(df):\n",
    "    \"\"\"\n",
    "    显示每个分组的具体范围\n",
    "    \"\"\"\n",
    "    bin_ranges = pd.IntervalIndex(pd.cut(df['hours_worked_per_week'], \n",
    "                                       bins=np.linspace(0, 99, 11), \n",
    "                                       include_lowest=True, \n",
    "                                       right=False))\n",
    "    unique_ranges = bin_ranges.unique()\n",
    "    print(\"工作时间区间范围：\")\n",
    "    for i, interval in enumerate(unique_ranges):\n",
    "        print(f\"区间 {i}: {interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def count_workers_by_hours_bin(morg_df):\n",
    "    \"\"\"\n",
    "    计算每个工作时间区间中的人数\n",
    "    \n",
    "    Args:\n",
    "        morg_df: 包含hours_bin列的DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (counts_method1, counts_method2)\n",
    "            - counts_method1: 使用value_counts()的结果\n",
    "            - counts_method2: 使用groupby().size()的结果\n",
    "    \"\"\"\n",
    "    # 验证输入\n",
    "    if 'hours_bin' not in morg_df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'hours_bin' column\")\n",
    "    \n",
    "    # 方法1：使用value_counts()\n",
    "    counts_method1 = morg_df['hours_bin'].value_counts().sort_index()\n",
    "    \n",
    "    # 方法2：使用groupby().size()\n",
    "    counts_method2 = morg_df.groupby('hours_bin').size()\n",
    "    \n",
    "    # 显示结果\n",
    "    print(\"方法1 - 使用value_counts():\")\n",
    "    print(counts_method1)\n",
    "    print(\"\\n方法2 - 使用groupby().size():\")\n",
    "    print(counts_method2)\n",
    "    \n",
    "    # 显示每个区间的具体范围\n",
    "    show_bin_ranges(morg_df)\n",
    "    \n",
    "    return counts_method1, counts_method2\n",
    "\n",
    "def show_bin_ranges(df):\n",
    "    \"\"\"\n",
    "    显示每个分组的具体范围\n",
    "    \"\"\"\n",
    "    bin_ranges = pd.IntervalIndex(pd.cut(df['hours_worked_per_week'], \n",
    "                                       bins=np.linspace(0, 99, 11), \n",
    "                                       include_lowest=True, \n",
    "                                       right=False))\n",
    "    unique_ranges = bin_ranges.unique()\n",
    "    print(\"\\n工作时间区间范围：\")\n",
    "    for i, interval in enumerate(unique_ranges):\n",
    "        print(f\"区间 {i}: {interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 假设我们已经有了包含hours_bin的DataFrame\n",
    "# 首先创建示例数据\n",
    "sample_data = {\n",
    "    'hours_worked_per_week': [0, 15, 30, 40, 45, 50, 60, 70, 80, 90, 95]\n",
    "}\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "# 添加工作时间分组\n",
    "df = add_hours_worked_bin(df)\n",
    "\n",
    "# 计算每个区间的人数\n",
    "counts1, counts2 = count_workers_by_hours_bin(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
